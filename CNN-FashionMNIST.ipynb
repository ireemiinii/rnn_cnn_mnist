{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Sdz1CbS6gbk"
   },
   "source": [
    "# FashionMNIST Exercise\n",
    "For these exercises we'll work with the <a href='https://www.kaggle.com/zalando-research/fashionmnist'>Fashion-MNIST</a> dataset, also available through <a href='https://pytorch.org/docs/stable/torchvision/index.html'><tt><strong>torchvision</strong></tt></a>. Like MNIST, this dataset consists of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes:\n",
    "0. T-shirt/top\n",
    "1. Trouser\n",
    "2. Pullover\n",
    "3. Dress\n",
    "4. Coat\n",
    "5. Sandal\n",
    "6. Shirt\n",
    "7. Sneaker\n",
    "8. Bag\n",
    "9. Ankle boot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0R2QeUM6gbk"
   },
   "source": [
    "## Perform standard imports, load the Fashion-MNIST dataset\n",
    "Run the cell below to load the libraries needed for this exercise and the Fashion-MNIST dataset.<br>\n",
    "PyTorch makes the Fashion-MNIST dataset available through <a href='https://pytorch.org/docs/stable/torchvision/datasets.html#fashion-mnist'><tt><strong>torchvision</strong></tt></a>. The first time it's called, the dataset will be downloaded onto your computer to the path specified. From that point, torchvision will always look for a local copy before attempting another download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1639402622590,
     "user": {
      "displayName": "Engin Tunalı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04365200986728431923"
     },
     "user_tz": -180
    },
    "id": "fr-hlHwz6gbl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_data = datasets.FashionMNIST(root='Data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.FashionMNIST(root='Data', train=False, download=True, transform=transform)\n",
    "\n",
    "class_names = ['T-shirt','Trouser','Sweater','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0awsXRpr6gbl"
   },
   "source": [
    "## 1. Create data loaders\n",
    "Use DataLoader to create a <tt>train_loader</tt> and a <tt>test_loader</tt>. Batch sizes should be 10 for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1639402624541,
     "user": {
      "displayName": "Engin Tunalı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04365200986728431923"
     },
     "user_tz": -180
    },
    "id": "UCd0Z8zY6gbm"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ux1V8LXF6gbn"
   },
   "source": [
    "## 2. Examine a batch of images\n",
    "Use DataLoader, <tt>make_grid</tt> and matplotlib to display the first batch of 10 images.<br>\n",
    "OPTIONAL: display the labels as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "executionInfo": {
     "elapsed": 641,
     "status": "ok",
     "timestamp": 1639402626605,
     "user": {
      "displayName": "Engin Tunalı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04365200986728431923"
     },
     "user_tz": -180
    },
    "id": "2Ghyamw56gbo",
    "outputId": "3dec7cd1-42a0-44fa-ac27-a761e2512dd1"
   },
   "outputs": [],
   "source": [
    "# IMAGES ONLY\n",
    "for images,labels in train_loader: \n",
    "    break\n",
    "\n",
    "im = make_grid(images, nrow=10)\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.imshow(np.transpose(im.numpy(), (1, 2, 0)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "executionInfo": {
     "elapsed": 558,
     "status": "ok",
     "timestamp": 1639402631876,
     "user": {
      "displayName": "Engin Tunalı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04365200986728431923"
     },
     "user_tz": -180
    },
    "id": "v0jnufyM6gbp",
    "outputId": "32006844-4496-4757-f9ad-db0f35cf13cf"
   },
   "outputs": [],
   "source": [
    "# IMAGES AND LABELS\n",
    "for images,labels in train_loader: \n",
    "    break\n",
    "\n",
    "print('Label: ', labels.numpy())\n",
    "print('Class: ', *np.array([class_names[i] for i in labels]))\n",
    "\n",
    "im = make_grid(images, nrow=10)\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.imshow(np.transpose(im.numpy(), (1, 2, 0)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqJcYDK76gbp"
   },
   "source": [
    "## Downsampling\n",
    "<h3>3. If a 28x28 image is passed through a Convolutional layer using a 5x5 filter, a step size of 1, and no padding, what is the resulting matrix size?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMSaMMX76gbp"
   },
   "source": [
    "<div style='border:1px black solid; padding:5px'>A 5x5 filter leaves a two-pixel border on each side, so the overall dimension is reduced by 4.<br>\n",
    "The result is a 24x24 matrix.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 539,
     "status": "ok",
     "timestamp": 1639402636442,
     "user": {
      "displayName": "Engin Tunalı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04365200986728431923"
     },
     "user_tz": -180
    },
    "id": "WJdf_PHB6gbp",
    "outputId": "d0ec9e75-3699-4ae5-ec7e-f0da918c8f36"
   },
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(1, 1, 5, 1)\n",
    "for x,labels in train_loader:\n",
    "    print('Orig size:',x.shape)\n",
    "    break\n",
    "x = conv(x)\n",
    "print('Down size:',x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntH0elW66gbp"
   },
   "source": [
    "### 4. If the sample from question 3 is then passed through a 2x2 MaxPooling layer, what is the resulting matrix size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24sr1izp6gbq"
   },
   "source": [
    "<div style='border:1px black solid; padding:5px'>\n",
    "If a 2x2 pooling layer is applied to a 24x24 matrix, each side is divided by two, and rounded down if necessary.<br>\n",
    "The result is a 12x12 matrix.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1639402641958,
     "user": {
      "displayName": "Engin Tunalı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04365200986728431923"
     },
     "user_tz": -180
    },
    "id": "mRNnALTU6gbq",
    "outputId": "5db2b386-9e1e-465c-ce11-ebe38dfe96a0"
   },
   "outputs": [],
   "source": [
    "# Run the code below to check your answer:\n",
    "x = F.max_pool2d(x, 2, 2)\n",
    "print('Down size:',x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Rtl9Ove6gbq"
   },
   "source": [
    "## CNN definition\n",
    "### 5. Define a convolutional neural network\n",
    "Define a CNN model that can be trained on the Fashion-MNIST dataset. The model should contain two convolutional layers, two pooling layers, and two fully connected layers. You can use any number of neurons per layer so long as the model takes in a 28x28 image and returns an output of 10. Portions of the definition have been filled in for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1639402645627,
     "user": {
      "displayName": "Engin Tunalı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04365200986728431923"
     },
     "user_tz": -180
    },
    "id": "rK90jjAy6gbq"
   },
   "outputs": [],
   "source": [
    "# DON'T WRITE HERE\n",
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        self.fc1 = nn.Linear(5*5*16, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 5*5*16)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = self.fc2(X)\n",
    "        return X\n",
    "    \n",
    "torch.manual_seed(101)\n",
    "model = ConvolutionalNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xk4pbUT6gbq"
   },
   "source": [
    "## Trainable parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNfX-Aww6gbq"
   },
   "source": [
    "### 6. What is the total number of trainable parameters (weights & biases) in the model above?\n",
    "Answers will vary depending on your model definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2PajXwl6gbr"
   },
   "source": [
    "<div style='border:1px black solid; padding:5px'>\n",
    "$\\quad\\begin{split}(1\\times6\\times3\\times3)+6+(6\\times16\\times3\\times3)+16+(400\\times100)+100+(100\\times10)+10 &=\\\\\n",
    "54+6+864+16+40000+100+1000+10 &= 42,050\\end{split}$<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1639402648207,
     "user": {
      "displayName": "Engin Tunalı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04365200986728431923"
     },
     "user_tz": -180
    },
    "id": "ECpqt_GU6gbr",
    "outputId": "9b3a5fc3-d108-484a-f843-fc66fc6437aa"
   },
   "outputs": [],
   "source": [
    "# Run the code below to check your answer:\n",
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')\n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6DivRoF6gbr"
   },
   "source": [
    "### 7. Define loss function & optimizer\n",
    "Define a loss function called \"criterion\" and an optimizer called \"optimizer\".<br>\n",
    "You can use any functions you want, although we used Cross Entropy Loss and Adam (learning rate of 0.001) respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1639402650018,
     "user": {
      "displayName": "Engin Tunalı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04365200986728431923"
     },
     "user_tz": -180
    },
    "id": "YqEY7lCl6gbr"
   },
   "outputs": [],
   "source": [
    "# DON'T WRITE HERE\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cJ6mDie6gbr"
   },
   "source": [
    "### 8. Train the model\n",
    "Don't worry about tracking loss values, displaying results, or validating the test set. Just train the model through 5 epochs. We'll evaluate the trained model in the next step.<br>\n",
    "OPTIONAL: print something after each epoch to indicate training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123625,
     "status": "ok",
     "timestamp": 1639402791784,
     "user": {
      "displayName": "Engin Tunalı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04365200986728431923"
     },
     "user_tz": -180
    },
    "id": "cV9n7iU76gbr",
    "outputId": "fb263285-a6af-4445-d718-0a87f0b9bfdd"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    \n",
    "    # Run the training batches\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        \n",
    "        # Apply the model\n",
    "        y_pred = model(X_train)  # we don't flatten X-train here\n",
    "        loss = criterion(y_pred, y_train)\n",
    " \n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        batch_corr = (predicted == y_train).sum() # Sum the true values\n",
    "        trn_corr += batch_corr\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        b+=1\n",
    "        \n",
    "        # Print interim results\n",
    "        if b%1000 == 0:\n",
    "            print(f'epoch: {i:2}  batch: {b:4} [{10*b:6}/60000]  loss: {loss.item():10.8f}  \\\n",
    "            accuracy: {trn_corr.item()*100/(10*b):7.3f}%')\n",
    "        \n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "        \n",
    "    # Run the testing batches\n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "\n",
    "            # Apply the model\n",
    "            y_val = model(X_test)\n",
    "\n",
    "            predicted = torch.max(y_val.data, 1)[1] \n",
    "            tst_corr += (predicted == y_test).sum()\n",
    "            \n",
    "    loss = criterion(y_val, y_test)\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(tst_corr)\n",
    "        \n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSpqWpHm6gbr"
   },
   "source": [
    "### 9. Evaluate the model\n",
    "Set <tt>model.eval()</tt> and determine the percentage correct out of 10,000 total test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1974,
     "status": "ok",
     "timestamp": 1639402796199,
     "user": {
      "displayName": "Engin Tunalı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04365200986728431923"
     },
     "user_tz": -180
    },
    "id": "54CwHtks6gbr",
    "outputId": "decd3c53-61db-41d4-cb3e-877f1ced02aa"
   },
   "outputs": [],
   "source": [
    "# DON'T WRITE HERE\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for X_test, y_test in test_loader:\n",
    "        y_val = model(X_test)\n",
    "        predicted = torch.max(y_val,1)[1]\n",
    "        correct += (predicted == y_test).sum()\n",
    "        \n",
    "print(f'Test accuracy: {correct.item()}/{len(test_data)} = {correct.item()*100/(len(test_data)):7.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1639402803653,
     "user": {
      "displayName": "Engin Tunalı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04365200986728431923"
     },
     "user_tz": -180
    },
    "id": "QQAcNNGy_YP0",
    "outputId": "9d18a8ad-e90a-42d5-8c72-f20d4af8d991"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    plt.plot(train_losses, label='training loss')\n",
    "    plt.plot(test_losses, label='validation loss')\n",
    "    plt.title('Loss at the end of each epoch')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1639402814662,
     "user": {
      "displayName": "Engin Tunalı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04365200986728431923"
     },
     "user_tz": -180
    },
    "id": "JdoKJCdM_g5V",
    "outputId": "48dfd7a3-5a36-4386-8235-295deb8e66d1"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    plt.plot([t/600 for t in train_correct], label='training accuracy')\n",
    "    plt.plot([t/100 for t in test_correct], label='validation accuracy')\n",
    "    plt.title('Accuracy at the end of each epoch')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpX-tze3VvOJ"
   },
   "source": [
    "## Evaluate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1639402819201,
     "user": {
      "displayName": "Engin Tunalı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04365200986728431923"
     },
     "user_tz": -180
    },
    "id": "mr5Iu9IuVvOJ"
   },
   "outputs": [],
   "source": [
    "# Extract the data all at once, not in batches\n",
    "test_load_all = DataLoader(test_data, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2378,
     "status": "ok",
     "timestamp": 1639402821965,
     "user": {
      "displayName": "Engin Tunalı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04365200986728431923"
     },
     "user_tz": -180
    },
    "id": "oaVezc-aVvOK",
    "outputId": "94cb2910-d6d3-4677-f9ef-f6811bf76f91"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for X_test, y_test in test_load_all:\n",
    "        y_val = model(X_test)  # we don't flatten the data this time\n",
    "        predicted = torch.max(y_val,1)[1]\n",
    "        correct += (predicted == y_test).sum()\n",
    "print(f'Test accuracy: {correct.item()}/{len(test_data)} = {correct.item()*100/(len(test_data)):7.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-73NcprVvOL"
   },
   "source": [
    "## Examine the misses\n",
    "We can track the index positions of \"missed\" predictions, and extract the corresponding image and label. We'll do this in batches to save screen space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 641,
     "status": "ok",
     "timestamp": 1639402827509,
     "user": {
      "displayName": "Engin Tunalı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04365200986728431923"
     },
     "user_tz": -180
    },
    "id": "1lurq_6_VvOL",
    "outputId": "7d9376af-accb-4f49-9903-6415cd9f92a9"
   },
   "outputs": [],
   "source": [
    "misses = np.array([])\n",
    "for i in range(len(predicted.view(-1))):\n",
    "    if predicted[i] != y_test[i]:\n",
    "        misses = np.append(misses,i).astype('int64')\n",
    "        \n",
    "# Display the number of misses\n",
    "len(misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1639402828343,
     "user": {
      "displayName": "Engin Tunalı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04365200986728431923"
     },
     "user_tz": -180
    },
    "id": "Q2D-RcgiVvOL",
    "outputId": "72743c94-393e-4e49-c9ec-78661bb7528b"
   },
   "outputs": [],
   "source": [
    "# Display the first 10 index positions\n",
    "misses[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1639402828905,
     "user": {
      "displayName": "Engin Tunalı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04365200986728431923"
     },
     "user_tz": -180
    },
    "id": "9lQP9KA5VvOM"
   },
   "outputs": [],
   "source": [
    "# Set up an iterator to feed batched rows\n",
    "r = 12   # row size\n",
    "row = iter(np.array_split(misses,len(misses)//r+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6xjZ8tQVvOM"
   },
   "source": [
    "Now that everything is set up, run and re-run the cell below to view all of the missed predictions.<br>\n",
    "Use <kbd>Ctrl+Enter</kbd> to remain on the cell between runs. You'll see a <tt>StopIteration</tt> once all the misses have been seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "executionInfo": {
     "elapsed": 414,
     "status": "ok",
     "timestamp": 1639402832045,
     "user": {
      "displayName": "Engin Tunalı",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04365200986728431923"
     },
     "user_tz": -180
    },
    "id": "Bic28sbUVvOM",
    "outputId": "7201376a-682e-4bcb-85be-93dfd45f04fd"
   },
   "outputs": [],
   "source": [
    "nextrow = next(row)\n",
    "print(\"Index:\", nextrow)\n",
    "print(\"Label:\", y_test.index_select(0,torch.tensor(nextrow)).numpy())\n",
    "print(\"Guess:\", predicted.index_select(0,torch.tensor(nextrow)).numpy())\n",
    "\n",
    "images = X_test.index_select(0,torch.tensor(nextrow))\n",
    "im = make_grid(images, nrow=r)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(np.transpose(im.numpy(), (1, 2, 0)));\n",
    "\n",
    "#class_names = ['T-shirt','Trouser','Sweater','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Boot']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN-FashionMNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
